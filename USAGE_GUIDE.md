# üìñ Gu√≠a de Uso del Scraper Gen√©rico

## üéØ Introducci√≥n

Este scraper ahora soporta configuraci√≥n completa mediante el archivo `data/urls_config.json`. Puedes a√±adir tantas URLs como necesites (recomendado: 10-15) con diferentes configuraciones de b√∫squeda.

---

## üìù Tipos de Configuraci√≥n

### 1Ô∏è‚É£ Conteo de Keywords en √Åreas Espec√≠ficas

Cuenta palabras clave en secciones espec√≠ficas del HTML.

```json
{
  "name": "Nombre descriptivo",
  "url": "https://tu-sitio.com/pagina",
  "keywords": ["palabra1", "palabra2", "palabra3"],
  "search_areas": {
    "titulo": "h1, h2, h3",
    "contenido": "article, .main-content",
    "requisitos": ".requirements, .skills-list"
  }
}
```

**Resultado en Excel:**
```
| timestamp | url | name | titulo_palabra1 | titulo_palabra2 | contenido_palabra1 | contenido_palabra2 | requisitos_palabra1 | ... |
```

**Cu√°ndo usar:** Cuando quieres saber d√≥nde aparecen las palabras (t√≠tulo vs contenido vs requisitos).

---

### 2Ô∏è‚É£ Conteo de Keywords en Toda la P√°gina

Cuenta palabras clave en todo el HTML sin distinguir √°reas.

```json
{
  "name": "Noticias Investigaci√≥n",
  "url": "https://universidad.edu/noticias",
  "keywords": ["investigaci√≥n", "doctorado", "beca", "publicaci√≥n"],
  "search_areas": null
}
```

**Resultado en Excel:**
```
| timestamp | url | name | investigaci√≥n | doctorado | beca | publicaci√≥n |
```

**Cu√°ndo usar:** Cuando solo te interesa el total de apariciones, sin importar d√≥nde.

---

### 3Ô∏è‚É£ Tipos Especiales (Heredados)

#### date_check - Verificaci√≥n de Fechas
```json
{
  "name": "UVigoProfesor",
  "url": "https://secretaria.uvigo.gal/uv/web/convocatoria/public/index",
  "type": "date_check"
}
```

**Resultado:** `status: YES/NO/ERROR`

#### keyword_check - Verificaci√≥n de Presencia
```json
{
  "name": "USCEmprego",
  "url": "https://www.usc.gal/gl/emprego",
  "type": "keyword_check",
  "keywords": ["psicolog"]
}
```

**Resultado:** `status: YES/NO/ERROR`

---

## üîç Selectores CSS - Gu√≠a R√°pida

### Ejemplos Comunes

| Selector | Significado | Ejemplo |
|----------|-------------|---------|
| `h1, h2` | Todos los h1 y h2 | T√≠tulos principales |
| `article` | Elemento article | Contenido principal |
| `.clase` | Elementos con clase | `.job-description` |
| `#id` | Elemento con ID | `#main-content` |
| `div.clase` | Div con clase | `div.job-card` |
| `p.intro` | P√°rrafos con clase intro | Introducci√≥n |

### Combinaciones √ötiles
```json
"search_areas": {
  "titulos": "h1, h2, h3, .title",
  "descripcion": "article, .description, .job-desc",
  "meta": ".tags, .categories, .keywords",
  "todo_principal": "main, #content, .main-wrapper"
}
```

---

## üí° Casos de Uso Reales

### Ejemplo 1: Portal de Empleo Universitario
```json
{
  "name": "Portal Empleo UV",
  "url": "https://empleo.uv.es/ofertas",
  "keywords": ["profesor", "investigador", "docente", "postdoc"],
  "search_areas": {
    "titulo": "h2.offer-title",
    "descripcion": ".offer-description",
    "requisitos": ".requirements"
  }
}
```

**Qu√© mide:** Frecuencia de cada t√©rmino en diferentes secciones de las ofertas.

---

### Ejemplo 2: Noticias de Investigaci√≥n
```json
{
  "name": "Noticias CSIC",
  "url": "https://www.csic.es/es/noticias",
  "keywords": ["neurociencia", "psicolog√≠a", "cognici√≥n", "cerebro"],
  "search_areas": null
}
```

**Qu√© mide:** Total de menciones de cada t√©rmino en toda la p√°gina de noticias.

---

### Ejemplo 3: Convocatorias M√∫ltiples
```json
[
  {
    "name": "Convocatorias UV",
    "url": "https://uv.es/convocatorias",
    "keywords": ["ayuda", "beca", "contrato"],
    "search_areas": {"titulo": "h3, h4"}
  },
  {
    "name": "Convocatorias UB",
    "url": "https://ub.edu/convocatorias",
    "keywords": ["ayuda", "beca", "contrato"],
    "search_areas": {"titulo": "h3, h4"}
  },
  {
    "name": "Convocatorias UAM",
    "url": "https://uam.es/convocatorias",
    "keywords": ["ayuda", "beca", "contrato"],
    "search_areas": {"titulo": "h3, h4"}
  }
]
```

**Qu√© mide:** Compara menciones de t√©rminos en los t√≠tulos de 3 universidades.

---

## üöÄ Workflow de Configuraci√≥n

### Paso 1: Identifica la P√°gina
1. Abre la p√°gina web en tu navegador
2. Inspecciona el HTML (F12 / Clic derecho > Inspeccionar)
3. Identifica las √°reas de inter√©s

### Paso 2: Encuentra los Selectores
```html
<!-- Ejemplo de HTML -->
<article class="job-post">
  <h2 class="job-title">Profesor de Psicolog√≠a</h2>
  <div class="job-description">
    Buscamos profesor con experiencia en neurociencia...
  </div>
  <ul class="requirements">
    <li>Doctorado en Psicolog√≠a</li>
    <li>Investigaci√≥n en cognici√≥n</li>
  </ul>
</article>
```

**Selectores correspondientes:**
```json
"search_areas": {
  "titulo": "h2.job-title, .job-title",
  "descripcion": ".job-description",
  "requisitos": ".requirements"
}
```

### Paso 3: Define las Keywords
Palabras clave relevantes para tu b√∫squeda:
```json
"keywords": ["psicolog√≠a", "neurociencia", "cognici√≥n", "doctorado"]
```

### Paso 4: A√±ade a urls_config.json
```json
{
  "name": "Nombre descriptivo para identificar",
  "url": "URL completa con https://",
  "keywords": ["lista", "de", "palabras"],
  "search_areas": {
    "area1": "selectores css",
    "area2": "otros selectores"
  }
}
```

### Paso 5: Prueba Localmente
```bash
python src/main.py
```

### Paso 6: Verifica el Excel
Abre `data/scraper_estudios.xlsx` y verifica que las columnas sean correctas.

---

## üîß Resoluci√≥n de Problemas

### Problema: No encuentra keywords
**Soluci√≥n:**
1. Verifica que las keywords est√©n en min√∫sculas (b√∫squeda case-insensitive)
2. Comprueba los selectores CSS inspeccionando el HTML
3. Prueba con `"search_areas": null` primero para buscar en toda la p√°gina

### Problema: Selectores no funcionan
**Soluci√≥n:**
1. Inspecciona el HTML real de la p√°gina
2. Usa selectores m√°s generales: `div`, `article`, `main`
3. Combina m√∫ltiples selectores: `"h1, h2, .title"`

### Problema: Muchas columnas en Excel
**Soluci√≥n:**
- Reduce el n√∫mero de keywords
- Reduce el n√∫mero de √°reas en `search_areas`
- Usa b√∫squeda general (`search_areas: null`)

### Problema: Timeout o errores de red
**Soluci√≥n:**
- Verifica que la URL sea accesible
- Comprueba que el sitio permita scraping (robots.txt)
- El rate limiting de 1 segundo est√° activo por defecto

---

## üìä Interpretaci√≥n de Resultados

### Ejemplo de Salida en Excel

```
| timestamp           | url              | name      | titulo_python | contenido_python | titulo_javascript |
|---------------------|------------------|-----------|---------------|------------------|-------------------|
| 2025-01-15 20:00:00 | https://ej.com   | Ofertas   | 5             | 12               | 3                 |
| 2025-01-17 20:00:00 | https://ej.com   | Ofertas   | 7             | 15               | 4                 |
```

**Interpretaci√≥n:**
- El 15/01: "python" apareci√≥ 5 veces en t√≠tulos y 12 en contenido
- El 17/01: "python" aument√≥ a 7 en t√≠tulos (¬°m√°s ofertas de Python!)
- "javascript" menos frecuente pero tambi√©n aument√≥

**Insights:**
- Tendencia al alza en ofertas de Python
- Mayor √©nfasis en Python que JavaScript
- Puedes comparar entre fechas para ver tendencias

---

## üéì Mejores Pr√°cticas

### ‚úÖ Recomendaciones

1. **Nombres descriptivos**: Usa nombres claros que identifiquen la fuente
2. **Keywords relevantes**: 4-8 keywords por configuraci√≥n
3. **√Åreas espec√≠ficas**: 2-4 √°reas m√°ximo para claridad
4. **URLs estables**: Evita p√°ginas que cambian estructura frecuentemente
5. **Respeta robots.txt**: El scraper ya implementa rate limiting de 1s

### ‚ùå Evitar

1. **Demasiadas keywords**: >15 keywords hace el Excel dif√≠cil de leer
2. **Selectores muy espec√≠ficos**: Pueden romperse si cambia el HTML
3. **URLs din√°micas**: Sitios que requieren JavaScript para cargar contenido
4. **Sitios que bloquean bots**: Respeta las pol√≠ticas de cada sitio

---

## üìû Soporte

Si necesitas ayuda:
1. Revisa este archivo y el `README.md`
2. Consulta `REVIEW.md` para detalles t√©cnicos
3. Mira `data/urls_config_example.json` para ejemplos
4. Inspecciona los comentarios en el c√≥digo fuente

---

**¬°El scraper est√° listo para usar!** üöÄ

Simplemente edita `data/urls_config.json`, haz commit, y el GitHub Action lo ejecutar√° autom√°ticamente martes y jueves a las 20:00.
